{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronitagarwala01/MED_263_Group_1/blob/main/MED263_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n"
      ],
      "metadata": {
        "id": "crLZpS9xuna-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Install and Import Libraries"
      ],
      "metadata": {
        "id": "h856IwWRZD_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title Install Dependencies: takes 1-2 minutes to run\n",
        "!pip install transformers datasets evaluate accelerate pillow torchvision scikit-learn"
      ],
      "metadata": {
        "id": "kpnlpABMxS-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd82aef-83a2-47a9-a0b2-3b5aa7d52ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DefaultDataCollator\n",
        "from transformers import AutoImageProcessor\n",
        "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wSJIS3avxoPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load Dataset"
      ],
      "metadata": {
        "id": "FIUU02A-up2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download data from github\n",
        "\n",
        "! git clone https://github.com/allbert4/MED_263_Group_1"
      ],
      "metadata": {
        "id": "QSG0H_9JBpXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Unpackage image data into Colab file system\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "zip_path = \"/content/MED_263_Group_1/HAM10000_sampled_100_balance.zip\"  # TODO\n",
        "extract_path = \"HAM10000_images\"\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Images extracted to:\", extract_path)\n"
      ],
      "metadata": {
        "id": "_y_pytgLyFjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load labels from Github data labels file\n",
        "import pandas as pd\n",
        "\n",
        "labels_path = \"/content/MED_263_Group_1/HAM10000_sampled_100bal_metadata.csv\"\n",
        "df = pd.read_csv(labels_path)\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "OsEQ6TryCWls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convert data to Huggingface dataset\n",
        "from datasets import Dataset\n",
        "\n",
        "base_path = extract_path + \"/HAM10000_sampled_100_balance/\"\n",
        "dataset_dict = {\n",
        "    \"image\": [os.path.join(base_path, img + \".jpg\") for img in df[\"image_id\"]],\n",
        "    \"label\": df[\"dx\"].tolist()\n",
        "}\n",
        "\n",
        "num_classes = len(set(df[\"dx\"]))\n",
        "\n",
        "dataset = Dataset.from_dict(dataset_dict)\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "VDl0gf-bCkup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check for missing images- should be 0\n",
        "missing_files = [img for img in dataset[\"image\"] if not os.path.exists(img)]\n",
        "print(f\"Missing images: {len(missing_files)}\")\n",
        "assert len(missing_files) == 0, \"Files not found, check your file directory paths\""
      ],
      "metadata": {
        "id": "AV-28f-EDAqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem: labels are strings. We need to convert them to integers\n",
        "# show example\n",
        "dataset[0]['label']"
      ],
      "metadata": {
        "id": "aSQ3kJ3KJuOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Assign indices to class labels\n",
        "\n",
        "unique_labels = sorted(set(dataset[\"label\"]))  # Ensure consistent ordering\n",
        "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "print(\"Label Mapping:\", label2id)"
      ],
      "metadata": {
        "id": "06_Oj0XDJLNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convert labels to integers\n",
        "\n",
        "def convert_labels(example):\n",
        "    example[\"label\"] = label2id[example[\"label\"]]\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(convert_labels)"
      ],
      "metadata": {
        "id": "QdzRaFlzJcIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now labels are integers!\n",
        "# Show example\n",
        "dataset[0]['label']"
      ],
      "metadata": {
        "id": "Nlp1Au1VJjPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Image Dataset\n",
        "from datasets import Image\n",
        "\n",
        "dataset = dataset.cast_column(\"image\", Image())"
      ],
      "metadata": {
        "id": "VHFFU1hJDVqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train/test data split\n",
        "split_dataset = dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]"
      ],
      "metadata": {
        "id": "eTqkiwO9Ddfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Data Visualization and Statistics"
      ],
      "metadata": {
        "id": "_ek7SXfTZPAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0])"
      ],
      "metadata": {
        "id": "aR0nVJYumWCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualize a few example images from each class\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "images = []\n",
        "for label in range(num_classes):\n",
        "    for example in train_dataset:\n",
        "      if example[\"label\"] == label:\n",
        "          image=example[\"image\"]\n",
        "          images.append(image)\n",
        "          break\n",
        "\n",
        "for cls, img in enumerate(images):\n",
        "  plt.subplot(3, 3, cls+1)\n",
        "  plt.imshow(images[cls], cmap=\"gray\")\n",
        "  plt.title(f\"Class {cls}: {id2label[cls]}\")\n",
        "\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "deJMvvyBWL8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next we visualize the distribution of our dataset."
      ],
      "metadata": {
        "id": "RRi08zSUhTr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labs = [example[\"label\"] for example in train_dataset]\n",
        "plt.hist(labs, bins=num_classes)\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Distribution of Train Set Classes')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "labs = [example[\"label\"] for example in test_dataset]\n",
        "plt.hist(labs, bins=num_classes)\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Distribution of Test Set Classes')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SMdSBEIhlah0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training data statistics\n",
        "\n",
        "# Label Statistics\n",
        "import seaborn as sns\n",
        "\n",
        "dx_col = df['dx']\n",
        "sns.countplot(x=dx_col, data=df)\n",
        "plt.title('Distribution of Class Labels')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nJbkDnPdSV8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Distribution for Diagnoses Type\n",
        "\n",
        "dx_type_col = df['dx_type']\n",
        "sns.countplot(x=dx_type_col, data=df)\n",
        "plt.title('Diagnoses Types')\n",
        "plt.xlabel('Diagnosis Type')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bu7xRvH6hb7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Distribution of Age of Patients\n",
        "\n",
        "age_col = df['age']\n",
        "sns.countplot(x=age_col, data=df)\n",
        "plt.title('Age of Patients')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2g8PbqOghsdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Distribution of Sex of Patients\n",
        "\n",
        "sex_col = df['sex']\n",
        "sns.countplot(x=sex_col, data=df)\n",
        "plt.title('Sex of Patients')\n",
        "plt.xlabel('Sex')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WDSUtqwciBmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Distribution of Localization\n",
        "\n",
        "localization_col = df['localization']\n",
        "sns.countplot(x=localization_col, data=df)\n",
        "plt.title('Localization of Patches')\n",
        "plt.xlabel('Localization')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KKRFggwRiHUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Load Models"
      ],
      "metadata": {
        "id": "PXxuJIF5u5qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load base model and image processor\n",
        "\n",
        "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "zckd0ydR7dRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Do some image transformations to make the model more resistant to overfitting, and crop to correct size for model\n",
        "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
        "\n",
        "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"]\n",
        "    if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "\n",
        "_transforms = Compose([\n",
        "    RandomResizedCrop(size),\n",
        "    ToTensor(),  # Convert to tensor\n",
        "    normalize  # Apply normalization\n",
        "])\n",
        "\n",
        "def transforms(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "    del examples[\"image\"]\n",
        "    return examples\n"
      ],
      "metadata": {
        "id": "5d54FAEO8NcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Preprocess over entire dataset\n",
        "train_dataset = train_dataset.with_transform(transforms)\n",
        "test_dataset = test_dataset.with_transform(transforms)"
      ],
      "metadata": {
        "id": "blCnvHti8oCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Batch examples\n",
        "from transformers import DefaultDataCollator\n",
        "data_collator = DefaultDataCollator()"
      ],
      "metadata": {
        "id": "C6qaTN7ALPLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set up evaluation metrics\n",
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "5-KoPqq19pi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5: Fine tune models"
      ],
      "metadata": {
        "id": "uir_bfR6vWhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title Set up model\n",
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "chtkh0pu9zqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Hyperparameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"tuned_model\",\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,                     # Learning rate\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    per_device_train_batch_size=16,         # Batch size train\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=16,          # Batch size eval\n",
        "    num_train_epochs=30,                     # Number of epochs\n",
        "    warmup_ratio=0.1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=image_processor\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "TbbQluSZ-ipT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 6: Evaluate Performance\n",
        "todo:\n",
        "-  Evaluate model performance on validation set using:\n",
        "  - Accuracy (using `evaluate.load(\"accuracy\")`)\n",
        "  - Precision, Recall, F1-score (using `precision_recall_fscore_support`)\n",
        "  - View the trend of loss and accuracy curve\n",
        "  - Confusion Matrix (for error analysis)\n"
      ],
      "metadata": {
        "id": "KiEy2LAIvrxZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX6LxGYGuhwx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "predictions_output = trainer.predict(test_dataset)\n",
        "\n",
        "predicted_labels = np.argmax(predictions_output.predictions, axis=1)\n",
        "\n",
        "true_labels = predictions_output.label_ids\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    if predictions.ndim > 1:\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    print(f\"Predictions shape: {predictions.shape}, Labels shape: {labels.shape}\")  # Debugging step\n",
        "\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted', zero_division=1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1-score\": f1\n",
        "    }\n",
        "\n",
        "metrics = compute_metrics((predicted_labels, true_labels))\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for log in trainer.state.log_history:\n",
        "    print(log) #Check whether loss decreases"
      ],
      "metadata": {
        "id": "ulaocoEYtldg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for epoch in range(1, int(trainer.state.epoch) + 1):\n",
        "    train_predictions = trainer.predict(train_dataset)\n",
        "    train_preds = train_predictions.predictions.argmax(axis=1)\n",
        "    train_labels = train_predictions.label_ids\n",
        "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    trainer.state.log_history.append({\"epoch\": epoch, \"train_accuracy\": train_accuracy})\n",
        "\n",
        "metrics = trainer.state.log_history\n",
        "\n",
        "train_loss = [entry[\"loss\"] for entry in metrics if \"loss\" in entry]\n",
        "test_loss = [entry[\"eval_loss\"] for entry in metrics if \"eval_loss\" in entry]\n",
        "\n",
        "train_accuracy = [entry[\"train_accuracy\"] for entry in metrics if \"train_accuracy\" in entry]\n",
        "test_accuracy = [entry[\"eval_accuracy\"] for entry in metrics if \"eval_accuracy\" in entry]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(13,4))\n",
        "\n",
        "# Loss Curve\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(train_loss, label=\"Train\")\n",
        "plt.plot(test_loss, label=\"Test\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "# Accuracy Curve\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(train_accuracy, label=\"Train\")\n",
        "plt.plot(test_accuracy, label=\"Test\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s8b8buKcT1co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique values in true_labels:\", np.unique(true_labels))\n",
        "print(\"Class distribution in true_labels:\", np.bincount(true_labels))\n"
      ],
      "metadata": {
        "id": "DrMgXxpABbfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "predictions_output = trainer.predict(test_dataset)\n",
        "predicted_labels = np.argmax(predictions_output.predictions, axis=1)\n",
        "true_labels = predictions_output.label_ids\n",
        "\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "MzM685v9KTBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "print(cm)\n",
        "\n",
        "all_labels = np.unique(np.concatenate((true_labels, predicted_labels)))\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.title(\"Confusion Matrix Heatmap\", fontsize=13)\n",
        "sns.heatmap(cm, cmap=\"Reds\", annot=True, fmt=\"d\", xticklabels=all_labels, yticklabels=all_labels)\n",
        "\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PCOx3NH2tqOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "correct_idxs = [i for i in range(len(true_labels)) if predicted_labels[i] == true_labels[i]]\n",
        "incorrect_idxs = [i for i in range(len(true_labels)) if predicted_labels[i] != true_labels[i]]\n",
        "\n",
        "sample_correct = random.sample(correct_idxs, min(4, len(correct_idxs)))\n",
        "sample_incorrect = random.sample(incorrect_idxs, min(4, len(incorrect_idxs)))\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "\n",
        "for i, idx in enumerate(sample_correct):\n",
        "    img = test_dataset[idx][\"pixel_values\"].permute(1, 2, 0).numpy()\n",
        "    axes[0, i].imshow(img)\n",
        "    axes[0, i].set_title(f\"✅ True: {id2label[true_labels[idx]]}\\nPredicted: {id2label[predicted_labels[idx]]}\")\n",
        "    axes[0, i].axis(\"off\")\n",
        "\n",
        "for i, idx in enumerate(sample_incorrect):\n",
        "    img = test_dataset[idx][\"pixel_values\"].permute(1, 2, 0).numpy()\n",
        "    axes[1, i].imshow(img)\n",
        "    axes[1, i].set_title(f\"❌ True: {id2label[true_labels[idx]]}\\nPredicted: {id2label[predicted_labels[idx]]}\")\n",
        "    axes[1, i].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u8TP7DLtUf04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step7: Model Optimization"
      ],
      "metadata": {
        "id": "bM-YxaXAXRJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Hyperparameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"tuned_model\",\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,                     # Learning rate\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    per_device_train_batch_size=16,         # Batch size train\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=16,          # Batch size eval\n",
        "    num_train_epochs=30,                     # Number of epochs\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=image_processor\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "kdAKQLT-Y8SN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}